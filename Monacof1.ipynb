{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4fdb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastf1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress FastF1 warnings for plotting as they can be noisy\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# --- Configuration Constants ---\n",
    "CACHE_DIR = r\"D:\\fastf1_cache\" # Consider making this dynamic or user-configurable in a real app\n",
    "FASTF1_YEAR = 2024\n",
    "FASTF1_ROUND = 8  # Monaco Grand Prix is typically round 8\n",
    "FASTF1_SESSION_TYPE = \"R\"  # 'R' for Race, 'Q' for Qualifying\n",
    "\n",
    "OPENWEATHER_API_KEY = \"b3d0fae0fe1583a97653b49954a298cf\" # Replace with your actual key in a production environment\n",
    "MONACO_LATITUDE = 43.7384\n",
    "MONACO_LONGITUDE = 7.4246\n",
    "MONACO_FORECAST_TIME = \"2025-05-25 13:00:00\" # Target forecast time (e.g., race start time)\n",
    "\n",
    "# --- Setup FastF1 Cache ---\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "fastf1.Cache.enable_cache(CACHE_DIR)\n",
    "\n",
    "# --- Data Loading and Preprocessing Functions ---\n",
    "\n",
    "def get_f1_session_lap_data(year: int, round_num: int, session_type: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads F1 session data, extracts lap and sector times, and converts them to seconds.\n",
    "    \"\"\"\n",
    "    print(f\"Loading {year} Round {round_num} {session_type} session data...\")\n",
    "    try:\n",
    "        session = fastf1.get_session(year, round_num, session_type)\n",
    "        session.load(telemetry=False, weather=False, messages=False) # Load only what's necessary\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading FastF1 session data: {e}\")\n",
    "        return pd.DataFrame() # Return empty DataFrame on error\n",
    "\n",
    "    # Select relevant lap data and drop NaNs\n",
    "    laps = session.laps[[\"Driver\", \"LapTime\", \"Sector1Time\", \"Sector2Time\", \"Sector3Time\"]].copy()\n",
    "    laps.dropna(subset=[\"LapTime\", \"Sector1Time\", \"Sector2Time\", \"Sector3Time\"], inplace=True)\n",
    "\n",
    "    # Convert lap and sector times to total seconds\n",
    "    for col in [\"LapTime\", \"Sector1Time\", \"Sector2Time\", \"Sector3Time\"]:\n",
    "        laps[f\"{col} (s)\"] = laps[col].dt.total_seconds()\n",
    "    \n",
    "    return laps\n",
    "\n",
    "def aggregate_sector_times(laps_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregates mean sector times per driver from lap data.\n",
    "    \"\"\"\n",
    "    sector_times = laps_df.groupby(\"Driver\").agg({\n",
    "        \"Sector1Time (s)\": \"mean\",\n",
    "        \"Sector2Time (s)\": \"mean\",\n",
    "        \"Sector3Time (s)\": \"mean\"\n",
    "    }).reset_index()\n",
    "\n",
    "    sector_times[\"TotalSectorTime (s)\"] = (\n",
    "        sector_times[\"Sector1Time (s)\"] +\n",
    "        sector_times[\"Sector2Time (s)\"] +\n",
    "        sector_times[\"Sector3Time (s)\"]\n",
    "    )\n",
    "    return sector_times\n",
    "\n",
    "def get_weather_forecast_data(lat: float, lon: float, api_key: str, target_time: str) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Fetches weather forecast data for a specific location and time.\n",
    "    Returns rain probability and temperature.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching weather forecast for {target_time}...\")\n",
    "    weather_url = f\"http://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={api_key}&units=metric\"\n",
    "    try:\n",
    "        response = requests.get(weather_url, timeout=10)\n",
    "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        weather_data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching weather data: {e}\")\n",
    "        return 0.0, 20.0 # Default values on error\n",
    "\n",
    "    forecast_data = next((f for f in weather_data.get(\"list\", []) if f.get(\"dt_txt\") == target_time), None)\n",
    "\n",
    "    if forecast_data:\n",
    "        rain_probability = forecast_data.get(\"pop\", 0.0)\n",
    "        temperature = forecast_data.get(\"main\", {}).get(\"temp\", 20.0)\n",
    "        print(f\"Weather forecast: Rain probability={rain_probability*100:.1f}%, Temperature={temperature:.1f}Â°C\")\n",
    "        return rain_probability, temperature\n",
    "    else:\n",
    "        print(f\"No forecast found for {target_time}. Using default values.\")\n",
    "        return 0.0, 20.0 # Default values if time not found\n",
    "\n",
    "# --- Hardcoded Data Functions (to be replaced by API calls post-event) ---\n",
    "\n",
    "def get_2025_qualifying_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads hardcoded 2025 Monaco qualifying data.\n",
    "    In a real scenario post-event, this would come from fastf1 API.\n",
    "    \"\"\"\n",
    "    print(\"Loading hardcoded 2025 qualifying data...\")\n",
    "    # NOTE: In a real scenario post-2025 Monaco GP, this would be fetched via fastf1:\n",
    "    # session_2025_q = fastf1.get_session(2025, FASTF1_ROUND, \"Q\")\n",
    "    # session_2025_q.load()\n",
    "    # q_laps = session_2025_q.laps.pick_fastest()\n",
    "    # quali_data = q_laps[['Driver', 'LapTime']].copy()\n",
    "    # quali_data['QualifyingTime (s)'] = quali_data['LapTime'].dt.total_seconds()\n",
    "    # return quali_data\n",
    "\n",
    "    # Changed driver names to 3-letter abbreviations for consistency\n",
    "    return pd.DataFrame({\n",
    "        \"Driver\": [\"VER\", \"NOR\", \"PIA\", \"RUS\", \"SAI\", \"ALB\", \"LEC\", \"OCO\",\n",
    "                   \"HAM\", \"STR\", \"GAS\", \"ALO\", \"HUL\", \"LAW\", \"HAD\", \"TSU\"],\n",
    "        \"QualifyingTime (s)\": [\n",
    "            70.669,  # VER (1:10.669)\n",
    "            69.954,  # NOR (1:09.954)\n",
    "            70.129,  # PIA (1:10.129)\n",
    "            np.nan,    # RUS (DNF) - using NaN for missing values\n",
    "            71.362,  # SAI (1:11.362)\n",
    "            71.213,  # ALB (1:11.213)\n",
    "            70.063,  # LEC (1:10.063)\n",
    "            70.942,  # OCO (1:10.942)\n",
    "            70.382,  # HAM (1:10.382)\n",
    "            72.563,  # STR (1:12.563)\n",
    "            71.994,  # GAS (1:11.994)\n",
    "            70.924,  # ALO (1:10.924)\n",
    "            71.596,   # HUL (1:11.596)\n",
    "            71.129, # LAW (1:11.129)\n",
    "            70.923, # HAD (1:10.923)\n",
    "            71.415 # TSU (1:11.415)\n",
    "        ]\n",
    "    })\n",
    "\n",
    "def get_clean_air_race_pace() -> dict:\n",
    "    \"\"\"\n",
    "    Loads hardcoded clean air race pace data.\n",
    "    In a real scenario post-event, this would be derived from 2025 race lap data.\n",
    "    \"\"\"\n",
    "    print(\"Loading hardcoded clean air race pace data...\")\n",
    "    # NOTE: Values are fictitious for 2025 data\n",
    "    # Changed driver names to 3-letter abbreviations for consistency\n",
    "    return {\n",
    "        \"VER\": 93.191067, \"HAM\": 94.020622, \"LEC\": 93.418667, \"NOR\": 93.428600, \"ALO\": 94.784333,\n",
    "        \"PIA\": 93.232111, \"RUS\": 93.833378, \"SAI\": 94.497444, \"STR\": 95.318250, \"HUL\": 95.345455,\n",
    "        \"OCO\": 95.682128, \"ALB\": 95.500000, \"GAS\": 95.100000,\n",
    "        \"LAW\": 96.000000, \"HAD\": 95.800000, \"TSU\": 94.500000 # Added new drivers\n",
    "    }\n",
    "\n",
    "def get_constructor_data() -> tuple[dict, dict]:\n",
    "    \"\"\"\n",
    "    Loads hardcoded team points and driver-to-team mapping.\n",
    "    In a real scenario, team points could come from an F1 standings API.\n",
    "    Driver-to-team could come from fastf1 session data or an external source.\n",
    "    \"\"\"\n",
    "    print(\"Loading hardcoded constructor and driver-to-team data...\")\n",
    "    team_points = {\n",
    "        \"McLaren\": 279, \"Mercedes\": 147, \"Red Bull\": 131, \"Williams\": 51, \"Ferrari\": 114,\n",
    "        \"Haas\": 20, \"Aston Martin\": 14, \"Kick Sauber\": 6, \"Racing Bulls\": 10, \"Alpine\": 7\n",
    "    }\n",
    "    # Normalize team points to a performance score between 0 and 1\n",
    "    max_points = max(team_points.values())\n",
    "    team_performance_score = {team: points / max_points for team, points in team_points.items()}\n",
    "\n",
    "    # Changed driver names to 3-letter abbreviations for consistency\n",
    "    driver_to_team = {\n",
    "        \"VER\": \"Red Bull\", \"NOR\": \"McLaren\", \"PIA\": \"McLaren\", \"LEC\": \"Ferrari\", \"RUS\": \"Mercedes\",\n",
    "        \"HAM\": \"Mercedes\", \"GAS\": \"Alpine\", \"ALO\": \"Aston Martin\", \"TSU\": \"Red Bull\",\n",
    "        \"SAI\": \"Williams\", \"HUL\": \"Kick Sauber\", \n",
    "        \"OCO\": \"Alpine\", \"STR\": \"Aston Martin\", \"ALB\": \"Williams\",\n",
    "        \"LAW\": \"Racing Bulls\", \"HAD\": \"Racing Bulls\" # Added new drivers for consistent team mapping\n",
    "    }\n",
    "    return team_performance_score, driver_to_team\n",
    "\n",
    "def get_average_monaco_position_change() -> dict:\n",
    "    \"\"\"\n",
    "    Loads hardcoded average position change data for Monaco.\n",
    "    In a real scenario, this would be derived from historical F1 data.\n",
    "    \"\"\"\n",
    "    print(\"Loading hardcoded average Monaco position change data...\")\n",
    "    # Changed driver names to 3-letter abbreviations for consistency\n",
    "    # NOTE: Add entries for new drivers if you have historical data for them.\n",
    "    # Otherwise, they will get NaN for this feature.\n",
    "    return {\n",
    "        \"VER\": -1.0, \"NOR\": 1.0, \"PIA\": 0.2, \"RUS\": 0.5, \"SAI\": -0.3, \"ALB\": 0.8,\n",
    "        \"LEC\": -1.5, \"OCO\": -0.2, \"HAM\": 0.3, \"STR\": 1.1, \"GAS\": -0.4, \"ALO\": -0.6,\n",
    "        \"HUL\": 0.0, \"LAW\": 0, \"HAD\":0, \"TSU\": -0.2 # Added new drivers\n",
    "    }\n",
    "\n",
    "# --- Main Data Preparation Function ---\n",
    "\n",
    "def prepare_modeling_data(\n",
    "    qualifying_df: pd.DataFrame,\n",
    "    sector_times_df: pd.DataFrame,\n",
    "    rain_prob: float,\n",
    "    temp: float,\n",
    "    team_scores: dict,\n",
    "    driver_team_map: dict,\n",
    "    avg_pos_change: dict,\n",
    "    laps_2024_df: pd.DataFrame # To ensure drivers are valid for y target\n",
    ") -> tuple[pd.DataFrame, pd.Series, pd.DataFrame, list]:\n",
    "    \"\"\"\n",
    "    Merges all input data into a single DataFrame for modeling and defines features (X) and target (y).\n",
    "    \"\"\"\n",
    "    print(\"Preparing data for modeling...\")\n",
    "\n",
    "    # Add Clean Air Race Pace, Team Performance Score, and Average Position Change\n",
    "    qualifying_df[\"CleanAirRacePace (s)\"] = qualifying_df[\"Driver\"].map(get_clean_air_race_pace())\n",
    "    qualifying_df[\"Team\"] = qualifying_df[\"Driver\"].map(driver_team_map)\n",
    "    qualifying_df[\"TeamPerformanceScore\"] = qualifying_df[\"Team\"].map(team_scores)\n",
    "    qualifying_df[\"AveragePositionChange\"] = qualifying_df[\"Driver\"].map(avg_pos_change)\n",
    "\n",
    "    # Merge qualifying and sector times data\n",
    "    merged_data = qualifying_df.merge(\n",
    "        sector_times_df[[\"Driver\", \"TotalSectorTime (s)\"]], on=\"Driver\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Add weather data\n",
    "    merged_data[\"RainProbability\"] = rain_prob\n",
    "    merged_data[\"Temperature\"] = temp\n",
    "\n",
    "    # --- Important Note on Wet Performance Factor ---\n",
    "    # The original code had:\n",
    "    # if rain_probability >= 0.75:\n",
    "    #     qualifying_2025[\"QualifyingTime\"] = qualifying_2025[\"QualifyingTime (s)\"] * qualifying_2025[\"WetPerformanceFactor\"]\n",
    "    # else:\n",
    "    #     qualifying_2025[\"QualifyingTime\"] = qualifying_2025[\"QualifyingTime (s)\"]\n",
    "    # However, \"WetPerformanceFactor\" was not defined anywhere.\n",
    "    # For a robust model, you would need to define/calculate this factor for each driver/team\n",
    "    # based on their historical wet performance. For this version, I'll assume QualifyingTime\n",
    "    # is the direct input and if wet factor were added, it would be another feature or an\n",
    "    # adjustment to the input.\n",
    "    merged_data[\"QualifyingTime\"] = merged_data[\"QualifyingTime (s)\"] # Ensure this is the final column name used\n",
    "\n",
    "    # Filter for drivers present in the 2024 lap data (our target source)\n",
    "    # This is where the driver name consistency is crucial.\n",
    "    valid_drivers = merged_data[\"Driver\"].isin(laps_2024_df[\"Driver\"].unique())\n",
    "    modeling_data = merged_data[valid_drivers].copy()\n",
    "\n",
    "    # Define features (X) and target (y)\n",
    "    features = [\n",
    "        \"QualifyingTime\", \"RainProbability\", \"Temperature\", \"TeamPerformanceScore\",\n",
    "        \"CleanAirRacePace (s)\", \"AveragePositionChange\"\n",
    "    ]\n",
    "    X = modeling_data[features]\n",
    "\n",
    "    # Align y target with the drivers in X\n",
    "    y = laps_2024_df.groupby(\"Driver\")[\"LapTime (s)\"].mean().reindex(modeling_data[\"Driver\"])\n",
    "\n",
    "    # Drop rows where y is NaN (drivers in X but not in 2024 laps, if any, after reindex)\n",
    "    nan_y_drivers = y[y.isna()].index.tolist()\n",
    "    if nan_y_drivers:\n",
    "        print(f\"Warning: Dropping drivers with no 2024 lap data for target (y): {nan_y_drivers}\")\n",
    "        X = X.drop(nan_y_drivers)\n",
    "        y = y.dropna()\n",
    "        modeling_data = modeling_data[~modeling_data[\"Driver\"].isin(nan_y_drivers)].copy()\n",
    "\n",
    "    return X, y, modeling_data, features\n",
    "\n",
    "# --- Model Training and Prediction ---\n",
    "\n",
    "def train_and_predict_model(X: pd.DataFrame, y: pd.Series) -> tuple[GradientBoostingRegressor, pd.DataFrame, pd.Series, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Imputes missing values, splits data, trains a Gradient Boosting Regressor,\n",
    "    and makes predictions.\n",
    "    Returns: model, X_imputed_df, y_test (Series), y_pred_test (ndarray), predicted_race_times (ndarray)\n",
    "    \"\"\"\n",
    "    print(\"Training and predicting with Gradient Boosting Regressor...\")\n",
    "\n",
    "    # Impute missing values for features\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    X_imputed_df = pd.DataFrame(X_imputed, columns=X.columns, index=X.index)\n",
    "\n",
    "    # Train-test split\n",
    "    # Check if there's enough data for splitting after imputation\n",
    "    if len(X_imputed_df) < 2: # Need at least 2 samples for train_test_split\n",
    "        print(\"Error: Not enough samples for train-test split after imputation.\")\n",
    "        return None, X_imputed_df, pd.Series(), np.array([]), np.array([]) # Return empty arrays/Series for prediction\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_imputed_df, y, test_size=0.3, random_state=37)\n",
    "\n",
    "    # Train gradient boosting model\n",
    "    model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.7, max_depth=3, random_state=37)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the full imputed dataset\n",
    "    predicted_race_times = model.predict(X_imputed_df)\n",
    "\n",
    "    # Calculate model error on the test set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    print(f\"Model Error (MAE): {mae:.2f} seconds\")\n",
    "\n",
    "    return model, X_imputed_df, y_test, y_pred_test, predicted_race_times\n",
    "\n",
    "# --- Visualization Functions ---\n",
    "\n",
    "def plot_lap_time_distribution(laps_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Plots the distribution of 2024 race lap times.\n",
    "    \"\"\"\n",
    "    if laps_df.empty: return\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(laps_df[\"LapTime (s)\"], bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "    plt.xlabel(\"Lap Time (s)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Distribution of 2024 Monaco Race Lap Times\")\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.show()\n",
    "\n",
    "def plot_quali_vs_race_pace(qualifying_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Plots 2025 Qualifying Time vs. Clean Air Race Pace.\n",
    "    \"\"\"\n",
    "    # Ensure there's data to plot after mapping\n",
    "    df = qualifying_df.dropna(subset=[\"QualifyingTime (s)\", \"CleanAirRacePace (s)\"])\n",
    "    if df.empty:\n",
    "        print(\"Not enough data to plot Qualifying Time vs. Clean Air Race Pace.\")\n",
    "        return\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(df[\"QualifyingTime (s)\"], df[\"CleanAirRacePace (s)\"], color='teal', alpha=0.7)\n",
    "    for i, driver in df.iterrows():\n",
    "        plt.annotate(driver[\"Driver\"], (driver[\"QualifyingTime (s)\"], driver[\"CleanAirRacePace (s)\"]),\n",
    "                     xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "    plt.xlabel(\"2025 Qualifying Time (s)\")\n",
    "    plt.ylabel(\"Clean Air Race Pace (s) (Derived)\")\n",
    "    plt.title(\"Qualifying Time vs. Clean Air Race Pace by Driver\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_team_performance(team_scores: dict):\n",
    "    \"\"\"\n",
    "    Plots a bar chart of normalized team performance scores.\n",
    "    \"\"\"\n",
    "    if not team_scores: return\n",
    "    sorted_teams = sorted(team_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    teams = [item[0] for item in sorted_teams]\n",
    "    scores = [item[1] for item in sorted_teams]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(teams, scores, color='lightcoral')\n",
    "    plt.xlabel(\"Normalized Performance Score\")\n",
    "    plt.title(\"Normalized Team Performance Score\")\n",
    "    plt.gca().invert_yaxis() # Puts highest score at the top\n",
    "    plt.grid(axis='x', alpha=0.75)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_average_position_change(avg_pos_change: dict):\n",
    "    \"\"\"\n",
    "    Plots a bar chart of average position change at Monaco.\n",
    "    \"\"\"\n",
    "    if not avg_pos_change: return\n",
    "    sorted_drivers = sorted(avg_pos_change.items(), key=lambda item: item[1], reverse=False)\n",
    "    drivers = [item[0] for item in sorted_drivers]\n",
    "    changes = [item[1] for item in sorted_drivers]\n",
    "\n",
    "    colors = ['skyblue' if c >= 0 else 'lightgreen' for c in changes]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(drivers, changes, color=colors)\n",
    "    plt.xlabel(\"Average Position Change (Qualifying Pos - Finish Pos)\")\n",
    "    plt.title(\"Historical Average Position Change at Monaco\")\n",
    "    plt.gca().invert_yaxis() # Puts positive changes (losses) higher\n",
    "    plt.axvline(0, color='grey', linestyle='--', linewidth=0.8)\n",
    "    plt.grid(axis='x', alpha=0.75)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_predicted_vs_actual(y_test: pd.Series, y_pred_test: np.ndarray):\n",
    "    \"\"\"\n",
    "    Plots predicted vs. actual race times on the test set.\n",
    "    \"\"\"\n",
    "    # Check if arrays are empty using .size (for numpy arrays)\n",
    "    if y_test.size == 0 or y_pred_test.size == 0:\n",
    "        print(\"Not enough test data to plot Predicted vs. Actual.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(y_test, y_pred_test, alpha=0.7, color='purple')\n",
    "    plt.plot([min(y_test.min(), y_pred_test.min()), max(y_test.max(), y_pred_test.max())],\n",
    "             [min(y_test.min(), y_pred_test.min()), max(y_test.max(), y_pred_test.max())],\n",
    "             color='red', linestyle='--', label='Perfect Prediction (y=x)')\n",
    "    plt.xlabel(\"Actual Race Time (s) [2024 Data]\")\n",
    "    plt.ylabel(\"Predicted Race Time (s) [Model on 2024 Test Set]\")\n",
    "    plt.title(\"Model Performance: Predicted vs. Actual Race Times (Test Set)\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_permutation_importance(model: GradientBoostingRegressor, X_imputed: pd.DataFrame, y: pd.Series, features: list):\n",
    "    \"\"\"\n",
    "    Calculates and plots permutation importance for model features.\n",
    "    This is more robust for correlated features than tree-based feature importance.\n",
    "    \"\"\"\n",
    "    if X_imputed.empty or y.empty or len(X_imputed) < 2: # Need at least 2 samples for permutation_importance\n",
    "        print(\"Not enough data to calculate Permutation Importance.\")\n",
    "        return\n",
    "\n",
    "    print(\"Calculating Permutation Importance...\")\n",
    "    try:\n",
    "        # y needs to be an array for permutation_importance\n",
    "        result = permutation_importance(model, X_imputed, y.to_numpy(), n_repeats=10, random_state=37, n_jobs=-1)\n",
    "        sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.boxplot(result.importances[sorted_idx].T,\n",
    "                    vert=False, labels=np.array(features)[sorted_idx])\n",
    "        plt.xlabel(\"Permutation Importance\")\n",
    "        plt.title(\"Permutation Importance of Features\")\n",
    "        plt.grid(axis='x', alpha=0.75)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except ValueError as e:\n",
    "        print(f\"Error calculating Permutation Importance: {e}\")\n",
    "        print(\"This often happens if there's only one class/value in y or insufficient data.\")\n",
    "\n",
    "\n",
    "def plot_predicted_results(final_results_subset: pd.DataFrame, num_racers: int = 10):\n",
    "    \"\"\"\n",
    "    Plots the top N predicted racers and their times, with the winner at the top.\n",
    "    `final_results_subset` dataframe is expected to have 'Driver' and 'PredictedRaceTime (s)' columns,\n",
    "    and be already sorted by 'PredictedRaceTime (s)' ascending.\n",
    "    \"\"\"\n",
    "    if final_results_subset.empty: return\n",
    "    \n",
    "    # top_racers is already the subset passed from main\n",
    "    top_racers = final_results_subset.head(num_racers)\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.barh(top_racers[\"Driver\"], top_racers[\"PredictedRaceTime (s)\"], color='skyblue')\n",
    "    plt.xlabel(\"Predicted Race Time (s)\")\n",
    "    plt.ylabel(\"Driver\")\n",
    "    plt.title(f\"Predicted Top {num_racers} Racers for 2025 Monaco GP\")\n",
    "\n",
    "    # Invert the y-axis to move the fastest driver (which was at the bottom after barh) to the top.\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(axis='x', alpha=0.75)\n",
    "\n",
    "    # Add predicted times as labels on the bars\n",
    "    # Use iterrows for simpler column access\n",
    "    for i, row in top_racers.iterrows():\n",
    "        plt.text(row[\"PredictedRaceTime (s)\"], i, f'{row[\"PredictedRaceTime (s)\"]:.2f}s', va='center', ha='left', fontsize=9, color='black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Main Execution Flow ---\n",
    "def main():\n",
    "    print(\"--- F1 Race Prediction Project Start ---\")\n",
    "\n",
    "    # 1. Get 2024 Monaco Race Lap Data (for training target)\n",
    "    laps_2024 = get_f1_session_lap_data(FASTF1_YEAR, FASTF1_ROUND, FASTF1_SESSION_TYPE)\n",
    "    if laps_2024.empty:\n",
    "        print(\"Could not load 2024 lap data. Exiting.\")\n",
    "        return\n",
    "    sector_times_2024 = aggregate_sector_times(laps_2024)\n",
    "\n",
    "    # Plot distribution of 2024 lap times\n",
    "    plot_lap_time_distribution(laps_2024)\n",
    "\n",
    "    # 2. Get 2025 Qualifying Data (currently hardcoded, future API)\n",
    "    qualifying_2025 = get_2025_qualifying_data()\n",
    "    if qualifying_2025.empty:\n",
    "        print(\"Could not load 2025 qualifying data. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 3. Get Weather Forecast for 2025 Monaco GP\n",
    "    rain_probability, temperature = get_weather_forecast_data(\n",
    "        MONACO_LATITUDE, MONACO_LONGITUDE, OPENWEATHER_API_KEY, MONACO_FORECAST_TIME\n",
    "    )\n",
    "\n",
    "    # 4. Get Constructor & Driver Data (hardcoded, future API/derived)\n",
    "    team_performance_score, driver_to_team = get_constructor_data()\n",
    "\n",
    "    # 5. Get Average Monaco Position Change (hardcoded, future derived)\n",
    "    average_position_change_monaco = get_average_monaco_position_change()\n",
    "\n",
    "    # Plot input data characteristics\n",
    "    # Ensure correct driver names are passed to plot_quali_vs_race_pace\n",
    "    plot_quali_vs_race_pace(qualifying_2025.merge(\n",
    "        pd.DataFrame(get_clean_air_race_pace().items(), columns=['Driver', 'CleanAirRacePace (s)']), on='Driver', how='left'))\n",
    "    plot_team_performance(team_performance_score)\n",
    "    plot_average_position_change(average_position_change_monaco)\n",
    "\n",
    "\n",
    "    # 6. Prepare Data for Modeling\n",
    "    X, y, modeling_data, features = prepare_modeling_data(\n",
    "        qualifying_2025, sector_times_2024, rain_probability, temperature,\n",
    "        team_performance_score, driver_to_team, average_position_change_monaco,\n",
    "        laps_2024 # Pass 2024 laps for driver validation\n",
    "    )\n",
    "\n",
    "    if X.empty or y.empty:\n",
    "        print(\"Insufficient data after preparation for modeling. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 7. Train Model and Predict\n",
    "    model, X_imputed_df, y_test, y_pred_test, predicted_race_times = train_and_predict_model(X, y)\n",
    "\n",
    "    # Check if model training/prediction was successful (e.g., if model is not None)\n",
    "    if model is None or X_imputed_df.empty or y_test.size == 0:\n",
    "        print(\"Model training or prediction failed due to insufficient data. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Add predictions to the original modeling data for final results display\n",
    "    # Ensure modeling_data has the same index as X_imputed_df for correct alignment\n",
    "    # This might be redundant if modeling_data was directly used to create X_imputed_df, but safer.\n",
    "    modeling_data = modeling_data.loc[X_imputed_df.index].copy()\n",
    "    modeling_data[\"PredictedRaceTime (s)\"] = predicted_race_times\n",
    "\n",
    "\n",
    "    # 8. Display Results and Visualizations\n",
    "    final_results = modeling_data.sort_values(\"PredictedRaceTime (s)\").reset_index(drop=True)\n",
    "\n",
    "    print(\"\\nð Predicted 2025 Monaco GP Winner ð\\n\")\n",
    "    print(final_results[[\"Driver\", \"PredictedRaceTime (s)\"]])\n",
    "\n",
    "    #print(\"\\nð Predicted Top 10 Racers ð\")\n",
    "    #plot_predicted_results(final_results[[\"Driver\", \"PredictedRaceTime (s)\"]], num_racers=10)\n",
    "\n",
    "\n",
    "    # Plot model performance\n",
    "    # plot_predicted_vs_actual(y_test, y_pred_test)\n",
    "\n",
    "    # Plot feature importances (using Permutation Importance)\n",
    "    plot_permutation_importance(model, X_imputed_df, y, features)\n",
    "\n",
    "    print(\"\\n--- F1 Race Prediction Project End ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
